weather_forecast_features: [ 'wind_speed_10m', 'grad_accum_ground_0m', 'pres_instant_ground_0m', 't_instant_ground_2m', 'r_instant_ground_2m' ]
weather_actuals_features: [ 'wind_speed', 'global_radiation', 'air_pressure', 'air_temperature', 'relative_humidity' ]

model_class: 'TFT'
run_with_validation: true
gpu_enable: true
trials: 2
num_workers: 1 # how many parallels for running the optimization
run_learning_rate_finder: false

# from "Application of Temporal Fusion Transformer for Day-Ahead PV Power Forecasting"
tft_config:
  input_chunk_length:
    start: 672 # 7*24*4 (one week)
    end: 672
    increment: 0
  output_chunk_length: 96 #1*24 (one day)
  hidden_size:
    start: 4
    end: 8
    increment: 4
  hidden_continuous_size: #[16, 32, 64]
    start: 2
    end: 4
    increment: 0
  num_attention_heads:
    start: 1
    end: 2
    increment: 1
  lstm_layers:
    start: 2
    end: 2
    increment: 0
  batch_size:
    start: 8
    end: 8
    increment: 0
  n_epochs: 1
  dropout:
    start: 0.1
    end: 0.7
    increment: 0
  use_static_covariates: [ true ]
  add_relative_index: [ false ]
  optimizer_kwargs:
    lr: 0.001
  #  random_state: 42
  #  save_checkpoints: true
  loss_fn: "MSE" # Custom or MSE or similar metrics
  weights:
    no_neg_pred_night:
        start: 0
        end: 1
        increment: 0.5
    no_neg_pred_nonpv:
        start: 0
        end: 1
        increment: 0.5
    morning_evening_peaks:
        start: 0
        end: 1
        increment: 0
    air_co:
        start: 0
        end: 1
        increment: 0

## tiny config for local training
#tft_config:
#  input_chunk_length: 672 # 7*24*4
#  output_chunk_length: 96 #1*24
#  # hidden_size: 32
#  # lstm_layers: 2
#  # batch_size: 16
#  n_epochs: 4
#  # dropout: 0.1
#  use_static_covariates: true
#  add_relative_index: false
#  optimizer_kwargs:
#   lr: 0.04365158322401657
#  random_state: 42
#  save_checkpoints: true
#  loss_fn: "Custom" # else MSE or similar metrics


#lstm_config:
#  training_length: 672
#  input_chunk_length: 672 # 7*24*4
#  hidden_dim: 20
#  dropout: 0.1
#  batch_size: 32
#  n_epochs: 1
#  model_name: "LSTM_P4_with_CustomLoss"
#  log_tensorboard: True
#  random_state: 42
#  #  loss_fn: "Custom"
#  force_reset: True
#  save_checkpoints: True
##  optimizer_kwargs:
##    lr: 0.001
